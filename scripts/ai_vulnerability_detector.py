#!/usr/bin/env python3
"""
Auto-Guardian AI Vulnerability Detector
Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ø«ØºØ±Ø§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ©

Ø§Ù„Ø¥ØµØ¯Ø§Ø±: 1.0.0
ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ­Ø¯ÙŠØ«: 2024-01-28

ÙŠØ³ØªØ®Ø¯Ù… Ù‡Ø°Ø§ Ø§Ù„Ù†Ø¸Ø§Ù… ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ù„Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ø«ØºØ±Ø§Øª Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©
"""

import os
import re
import json
import hashlib
import numpy as np
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from enum import Enum
from collections import defaultdict
import logging
from pathlib import Path

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class VulnerabilityCategory(Enum):
    """ÙØ¦Ø§Øª Ø§Ù„Ø«ØºØ±Ø§Øª"""
    INJECTION = "injection"
    AUTHENTICATION = "authentication"
    AUTHORIZATION = "authorization"
    SENSITIVE_DATA = "sensitive_data"
    CRYPTOGRAPHY = "cryptography"
    CONFIGURATION = "configuration"
    INPUT_VALIDATION = "input_validation"
    ERROR_HANDLING = "error_handling"
    LOGGING = "logging"
    COMMUNICATION = "communication"


class RiskLevel(Enum):
    """Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ù…Ø®Ø§Ø·Ø±"""
    CRITICAL = 5
    HIGH = 4
    MEDIUM = 3
    LOW = 2
    INFO = 1


@dataclass
class CodeFeature:
    """Ø³Ù…Ø© Ù…Ù† Ø³Ù…Ø§Øª Ø§Ù„ÙƒÙˆØ¯"""
    name: str
    value: float
    category: VulnerabilityCategory
    description: str


@dataclass
class AIDetection:
    """Ù†ØªÙŠØ¬Ø© Ø§Ù„ÙƒØ´Ù Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
    vulnerability_type: str
    category: VulnerabilityCategory
    risk_level: RiskLevel
    confidence: float
    evidence: List[str]
    context: Dict[str, Any]
    recommendations: List[str]
    affected_lines: List[int]
    cwe_id: str
    owasp_category: str


@dataclass
class AnalysisResult:
    """Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„"""
    scan_id: str
    target_file: str
    file_hash: str
    language: str
    total_lines: int
    features: List[CodeFeature]
    detections: List[AIDetection]
    overall_risk_score: int
    recommendations: List[str]
    analysis_time: float


class SimpleNeuralNetwork:
    """Ø´Ø¨ÙƒØ© Ø¹ØµØ¨ÙŠØ© Ø¨Ø³ÙŠØ·Ø© Ù„Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ø«ØºØ±Ø§Øª"""
    
    def __init__(self, input_size: int = 50, hidden_size: int = 32, output_size: int = 10):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø¹ØµØ¨ÙŠØ©"""
        np.random.seed(42)
        
        # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø¨Ø´ÙƒÙ„ Ø¹Ø´ÙˆØ§Ø¦ÙŠ
        self.weights1 = np.random.randn(input_size, hidden_size) * 0.1
        self.weights2 = np.random.randn(hidden_size, output_size) * 0.1
        self.bias1 = np.zeros((1, hidden_size))
        self.bias2 = np.zeros((1, output_size))
        
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.output_size = output_size
    
    def relu(self, x: np.ndarray) -> np.ndarray:
        """Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø´ÙŠØ· ReLU"""
        return np.maximum(0, x)
    
    def softmax(self, x: np.ndarray) -> np.ndarray:
        """Ø¯Ø§Ù„Ø© Softmax"""
        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))
        return exp_x / np.sum(exp_x, axis=1, keepdims=True)
    
    def forward(self, x: np.ndarray) -> np.ndarray:
        """Ø§Ù„ØªÙ…Ø±ÙŠØ± Ø§Ù„Ø£Ù…Ø§Ù…ÙŠ"""
        self.hidden = self.relu(np.dot(x, self.weights1) + self.bias1)
        self.output = self.softmax(np.dot(self.hidden, self.weights2) + self.bias2)
        return self.output
    
    def predict(self, features: np.ndarray) -> np.ndarray:
        """Ø§Ù„ØªÙ†Ø¨Ø¤"""
        return self.forward(features)


class FeatureExtractor:
    """Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ø³Ù…Ø§Øª Ù…Ù† Ø§Ù„ÙƒÙˆØ¯"""
    
    def __init__(self):
        self.feature_weights = {
            # Ø³Ù…Ø§Øª Ø§Ù„Ø­Ù‚Ù†
            'sql_keywords': 2.5,
            'dynamic_query': 3.0,
            'string_concat': 2.0,
            'user_input_usage': 2.5,
            
            # Ø³Ù…Ø§Øª Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø©
            'hardcoded_credentials': 3.5,
            'weak_password': 2.0,
            'missing_auth': 3.0,
            'session_handling': 2.5,
            
            # Ø³Ù…Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø©
            'sensitive_logging': 2.0,
            'cleartext_transmission': 3.0,
            'missing_encryption': 2.5,
            'key_management': 2.5,
            
            # Ø³Ù…Ø§Øª Ø§Ù„ØªÙƒÙˆÙŠÙ†
            'debug_enabled': 2.0,
            'default_credentials': 2.5,
            'missing_headers': 1.5,
            'error_exposure': 2.0,
            
            # Ø³Ù…Ø§Øª Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª
            'missing_validation': 2.5,
            'type_unsafe': 2.0,
            'size_unlimited': 1.5,
            'format_string': 2.5,
            
            # Ø³Ù…Ø§Øª Ø¹Ø§Ù…Ø©
            'code_complexity': 1.5,
            'file_operations': 2.0,
            'network_calls': 1.5,
            'reflection_usage': 2.0,
        }
    
    def extract_features(self, code: str, language: str) -> List[CodeFeature]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ù…Ø§Øª Ù…Ù† Ø§Ù„ÙƒÙˆØ¯"""
        features = []
        code_lower = code.lower()
        lines = code.split('\n')
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø³Ù…Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        feature_values = self._calculate_basic_features(code, code_lower, lines)
        
        for feature_name, value in feature_values.items():
            if feature_name in self.feature_weights:
                category = self._get_category_for_feature(feature_name)
                description = self._get_description_for_feature(feature_name)
                
                features.append(CodeFeature(
                    name=feature_name,
                    value=value * self.feature_weights[feature_name],
                    category=category,
                    description=description
                ))
        
        return features
    
    def _calculate_basic_features(self, code: str, code_lower: str, lines: List[str]) -> Dict[str, float]:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ø³Ù…Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©"""
        total_lines = len(lines)
        non_empty_lines = len([l for l in lines if l.strip()])
        
        features = {}
        
        # === Ø³Ù…Ø§Øª Ø§Ù„Ø­Ù‚Ù† (Injection) ===
        features['sql_keywords'] = self._count_patterns(code_lower, [
            'select ', 'insert ', 'update ', 'delete ', 'drop ', 'create ', 'alter '
        ]) / max(non_empty_lines, 1) * 100
        
        features['dynamic_query'] = self._count_patterns(code_lower, [
            'execute(', 'exec(', 'cursor.execute', 'raw_query', 'db.query'
        ]) / max(non_empty_lines, 1) * 100
        
        features['string_concat'] = self._count_patterns(code_lower, [
            ' + ', ' . ', '..', 'format(', 'f"', '%s', '{}'.format
        ]) / max(non_empty_lines, 1) * 100
        
        features['user_input_usage'] = self._count_patterns(code_lower, [
            'request.', 'input(', 'getparam', 'queryparam', 'body.', 'form.'
        ]) / max(non_empty_lines, 1) * 100
        
        # === Ø³Ù…Ø§Øª Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø© ===
        features['hardcoded_credentials'] = self._count_patterns(code_lower, [
            'password', 'api_key', 'secret', 'token', 'auth', 'credential'
        ]) / max(non_empty_lines, 1) * 100
        
        features['weak_password'] = self._count_patterns(code_lower, [
            'md5', 'sha1', 'crypt', 'base64'
        ]) / max(non_empty_lines, 1) * 100
        
        features['missing_auth'] = self._count_patterns(code_lower, [
            '@app.route', '@route', '@GetMapping', '@PostMapping'
        ]) / max(non_empty_lines, 1) * 100
        
        features['session_handling'] = self._count_patterns(code_lower, [
            'session', 'cookie', 'jwt', 'token', 'auth'
        ]) / max(non_empty_lines, 1) * 100
        
        # === Ø³Ù…Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø© ===
        features['sensitive_logging'] = self._count_patterns(code_lower, [
            'print(', 'console.log', 'logger.debug', 'logging.debug'
        ]) / max(non_empty_lines, 1) * 100
        
        features['cleartext_transmission'] = self._count_patterns(code_lower, [
            'http://', 'ftp://', 'telnet://'
        ]) / max(non_empty_lines, 1) * 100
        
        features['missing_encryption'] = self._count_patterns(code_lower, [
            'encrypt', 'decrypt', 'cipher', 'crypto'
        ]) / max(non_empty_lines, 1) * 100
        
        features['key_management'] = self._count_patterns(code_lower, [
            'key', 'iv', 'salt', 'nonce', 'secret'
        ]) / max(non_empty_lines, 1) * 100
        
        # === Ø³Ù…Ø§Øª Ø§Ù„ØªÙƒÙˆÙŠÙ† ===
        features['debug_enabled'] = self._count_patterns(code_lower, [
            'debug=true', 'debug=true', 'app.debug', 'debug=True'
        ]) / max(non_empty_lines, 1) * 100
        
        features['default_credentials'] = self._count_patterns(code_lower, [
            'admin', 'root', 'default', 'test'
        ]) / max(non_empty_lines, 1) * 100
        
        features['missing_headers'] = self._count_patterns(code_lower, [
            'content-type', 'x-frame-options', 'csp', 'x-content-type'
        ]) / max(non_empty_lines, 1) * 100
        
        features['error_exposure'] = self._count_patterns(code_lower, [
            'traceback', 'stack trace', 'exception', 'error:'
        ]) / max(non_empty_lines, 1) * 100
        
        # === Ø³Ù…Ø§Øª Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª ===
        features['missing_validation'] = self._count_patterns(code_lower, [
            'validate', 'sanitize', 'escape', 'filter'
        ]) / max(non_empty_lines, 1) * 100
        
        features['type_unsafe'] = self._count_patterns(code_lower, [
            'eval(', 'exec(', 'compile(', '.__class__'
        ]) / max(non_empty_lines, 1) * 100
        
        features['size_unlimited'] = self._count_patterns(code_lower, [
            'max_size', 'limit', 'buffer', 'overflow'
        ]) / max(non_empty_lines, 1) * 100
        
        features['format_string'] = self._count_patterns(code_lower, [
            '%s', '%d', '%f', 'format('
        ]) / max(non_empty_lines, 1) * 100
        
        # === Ø³Ù…Ø§Øª Ø¹Ø§Ù…Ø© ===
        features['code_complexity'] = self._calculate_complexity(code, lines)
        
        features['file_operations'] = self._count_patterns(code_lower, [
            'open(', 'read(', 'write(', 'file(', 'fopen', 'fs.open'
        ]) / max(non_empty_lines, 1) * 100
        
        features['network_calls'] = self._count_patterns(code_lower, [
            'http://', 'https://', 'fetch(', 'axios', 'requests.', 'http.client'
        ]) / max(non_empty_lines, 1) * 100
        
        features['reflection_usage'] = self._count_patterns(code_lower, [
            'åå°„', 'reflect', 'getattr', 'setattr', 'hasattr', 'getattribute'
        ]) / max(non_empty_lines, 1) * 100
        
        return features
    
    def _count_patterns(self, text: str, patterns: List[str]) -> int:
        """Ø¹Ø¯ ØªÙƒØ±Ø§Ø±Ø§Øª Ø§Ù„Ø£Ù†Ù…Ø§Ø·"""
        count = 0
        for pattern in patterns:
            count += text.count(pattern)
        return count
    
    def _calculate_complexity(self, code: str, lines: List[str]) -> float:
        """Ø­Ø³Ø§Ø¨ ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„ÙƒÙˆØ¯"""
        complexity = 0
        
        # Ø¹Ø¯ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª Ø§Ù„Ø´Ø±Ø·ÙŠØ©
        complexity += code.lower().count('if ')
        complexity += code.lower().count('elif ')
        complexity += code.lower().count('while ')
        complexity += code.lower().count('for ')
        
        # Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠØ©
        complexity += code.lower().count(' and ')
        complexity += code.lower().count(' or ')
        complexity += code.lower().count(' && ')
        complexity += code.lower().count(' || ')
        
        # Ø¹Ø¯ try-except
        complexity += code.lower().count('except ') * 2
        
        return min(100, (complexity / max(len(lines), 1)) * 100)
    
    def _get_category_for_feature(self, feature_name: str) -> VulnerabilityCategory:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ÙØ¦Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„Ø³Ù…Ø©"""
        category_mapping = {
            'sql_keywords': VulnerabilityCategory.INJECTION,
            'dynamic_query': VulnerabilityCategory.INJECTION,
            'string_concat': VulnerabilityCategory.INJECTION,
            'user_input_usage': VulnerabilityCategory.INPUT_VALIDATION,
            'hardcoded_credentials': VulnerabilityCategory.SENSITIVE_DATA,
            'weak_password': VulnerabilityCategory.CRYPTOGRAPHY,
            'missing_auth': VulnerabilityCategory.AUTHENTICATION,
            'session_handling': VulnerabilityCategory.AUTHENTICATION,
            'sensitive_logging': VulnerabilityCategory.LOGGING,
            'cleartext_transmission': VulnerabilityCategory.COMMUNICATION,
            'missing_encryption': VulnerabilityCategory.CRYPTOGRAPHY,
            'key_management': VulnerabilityCategory.CRYPTOGRAPHY,
            'debug_enabled': VulnerabilityCategory.CONFIGURATION,
            'default_credentials': VulnerabilityCategory.CONFIGURATION,
            'missing_headers': VulnerabilityCategory.CONFIGURATION,
            'error_exposure': VulnerabilityCategory.ERROR_HANDLING,
            'missing_validation': VulnerabilityCategory.INPUT_VALIDATION,
            'type_unsafe': VulnerabilityCategory.INPUT_VALIDATION,
            'size_unlimited': VulnerabilityCategory.INPUT_VALIDATION,
            'format_string': VulnerabilityCategory.INJECTION,
            'code_complexity': VulnerabilityCategory.ERROR_HANDLING,
            'file_operations': VulnerabilityCategory.CONFIGURATION,
            'network_calls': VulnerabilityCategory.COMMUNICATION,
            'reflection_usage': VulnerabilityCategory.INPUT_VALIDATION,
        }
        
        return category_mapping.get(feature_name, VulnerabilityCategory.CONFIGURATION)
    
    def _get_description_for_feature(self, feature_name: str) -> str:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ÙˆØµÙ Ø§Ù„Ø³Ù…Ø©"""
        descriptions = {
            'sql_keywords': 'ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© SQL ÙÙŠ Ø§Ù„ÙƒÙˆØ¯',
            'dynamic_query': 'Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ©',
            'string_concat': 'Ø±Ø¨Ø· Ø³Ù„Ø§Ø³Ù„ Ù†ØµÙŠØ©',
            'user_input_usage': 'Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…',
            'hardcoded_credentials': 'Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø¹ØªÙ…Ø§Ø¯ Ù…ÙØ¶Ù…ÙÙ‘Ù†Ø©',
            'weak_password': 'ÙƒÙ„Ù…Ø§Øª Ù…Ø±ÙˆØ± Ø¶Ø¹ÙŠÙØ©',
            'missing_auth': 'ÙÙ‚Ø¯Ø§Ù† Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø©',
            'session_handling': 'Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¬Ù„Ø³Ø§Øª',
            'sensitive_logging': 'ØªØ³Ø¬ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø§Ø³Ø©',
            'cleartext_transmission': 'Ø¥Ø±Ø³Ø§Ù„ ØºÙŠØ± Ù…Ø´ÙØ±',
            'missing_encryption': 'ÙÙ‚Ø¯Ø§Ù† Ø§Ù„ØªØ´ÙÙŠØ±',
            'key_management': 'Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…ÙØ§ØªÙŠØ­',
            'debug_enabled': 'ÙˆØ¶Ø¹ Ø§Ù„ØªØµØ­ÙŠØ­ Ù…ÙØ¹Ù„',
            'default_credentials': 'Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø¹ØªÙ…Ø§Ø¯ Ø§ÙØªØ±Ø§Ø¶ÙŠØ©',
            'missing_headers': 'Ø±Ø¤ÙˆØ³ HTTP Ù…ÙÙ‚ÙˆØ¯Ø©',
            'error_exposure': 'ÙƒØ´Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡',
            'missing_validation': 'ÙÙ‚Ø¯Ø§Ù† Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª',
            'type_unsafe': 'Ø£Ù†ÙˆØ§Ø¹ ØºÙŠØ± Ø¢Ù…Ù†Ø©',
            'size_unlimited': 'Ø¨Ø¯ÙˆÙ† ØªØ­Ø¯ÙŠØ¯ Ø­Ø¬Ù…',
            'format_string': 'Ø³Ù„Ø³Ù„Ø© Ø§Ù„ØªÙ†Ø³ÙŠÙ‚',
            'code_complexity': 'ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„ÙƒÙˆØ¯',
            'file_operations': 'Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ù„ÙØ§Øª',
            'network_calls': 'Ø§Ø³ØªØ¯Ø¹Ø§Ø¡Ø§Øª Ø§Ù„Ø´Ø¨ÙƒØ©',
            'reflection_usage': 'Ø§Ø³ØªØ®Ø¯Ø§Ù… Reflection',
        }
        
        return descriptions.get(feature_name, feature_name)


class AIVulnerabilityDetector:
    """Ù…ÙƒØªØ´Ù Ø§Ù„Ø«ØºØ±Ø§Øª Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
    
    def __init__(self):
        self.feature_extractor = FeatureExtractor()
        self.neural_network = SimpleNeuralNetwork(
            input_size=24,
            hidden_size=32,
            output_size=10
        )
        self._initialize_model()
    
    def _initialize_model(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ"""
        # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø£Ù…Ø«Ù„Ø© Ø£ÙˆÙ„ÙŠØ©
        training_data = self._generate_training_data()
        
        for epoch in range(100):
            for features, label in training_data:
                self.neural_network.forward(features.reshape(1, -1))
                # ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ØŒ ÙŠØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù‡Ù†Ø§
        
        logger.info("ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¨Ù†Ø¬Ø§Ø­")
    
    def _generate_training_data(self) -> List[Tuple[np.ndarray, int]]:
        """ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
        # ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ØŒ ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª
        return []
    
    def detect_vulnerabilities(self, file_path: str) -> AnalysisResult:
        """Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ø«ØºØ±Ø§Øª ÙÙŠ Ù…Ù„Ù"""
        import time
        start_time = time.time()
        
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            code = f.read()
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ù…Ø§Øª
        features = self.feature_extractor.extract_features(code, self._detect_language(file_path))
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…ØµÙÙˆÙØ© Ø§Ù„Ø³Ù…Ø§Øª
        feature_vector = self._features_to_vector(features)
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø¹ØµØ¨ÙŠØ©
        predictions = self.neural_network.predict(feature_vector.reshape(1, -1))[0]
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙƒØ´Ù
        detections = self._generate_detections(predictions, features, code, file_path)
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
        risk_score = self._calculate_risk_score(detections)
        
        # Ø§Ù„ØªÙˆØµÙŠØ§Øª
        recommendations = self._generate_recommendations(detections)
        
        return AnalysisResult(
            scan_id=hashlib.md5(f"{file_path}{time.time()}".encode()).hexdigest()[:8],
            target_file=file_path,
            file_hash=hashlib.md5(code.encode()).hexdigest(),
            language=self._detect_language(file_path),
            total_lines=len(code.split('\n')),
            features=features,
            detections=detections,
            overall_risk_score=risk_score,
            recommendations=recommendations,
            analysis_time=time.time() - start_time
        )
    
    def _detect_language(self, file_path: str) -> str:
        """Ø§ÙƒØªØ´Ø§Ù Ù„ØºØ© Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©"""
        extension = Path(file_path).suffix.lower()
        
        language_map = {
            '.py': 'Python',
            '.js': 'JavaScript',
            '.ts': 'TypeScript',
            '.java': 'Java',
            '.cs': 'C#',
            '.go': 'Go',
            '.rs': 'Rust',
            '.php': 'PHP',
            '.cpp': 'C++',
            '.c': 'C',
            '.rb': 'Ruby',
        }
        
        return language_map.get(extension, 'Unknown')
    
    def _features_to_vector(self, features: List[CodeFeature]) -> np.ndarray:
        """ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø³Ù…Ø§Øª Ø¥Ù„Ù‰ Ù…ØªØ¬Ù‡"""
        feature_names = list(self.feature_extractor.feature_weights.keys())
        vector = np.zeros(len(feature_names))
        
        feature_dict = {f.name: f.value for f in features}
        
        for i, name in enumerate(feature_names):
            vector[i] = feature_dict.get(name, 0)
        
        return vector
    
    def _generate_detections(
        self,
        predictions: np.ndarray,
        features: List[CodeFeature],
        code: str,
        file_path: str
    ) -> List[AIDetection]:
        """ØªÙˆÙ„ÙŠØ¯ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙƒØ´Ù"""
        detections = []
        lines = code.split('\n')
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ÙØ¦Ø§Øª Ø°Ø§Øª Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø§Ù„Ø¹Ø§Ù„ÙŠØ©
        categories = list(VulnerabilityCategory)
        high_prob_indices = np.argsort(predictions)[-5:][::-1]
        
        for idx in high_prob_indices:
            if predictions[idx] > 0.3:  # Ø¹ØªØ¨Ø© Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ©
                category = categories[idx]
                feature_list = [f for f in features if f.category == category]
                
                if feature_list:
                    detection = self._create_detection(
                        category,
                        predictions[idx],
                        feature_list,
                        lines,
                        file_path
                    )
                    detections.append(detection)
        
        return detections
    
    def _create_detection(
        self,
        category: VulnerabilityCategory,
        confidence: float,
        features: List[CodeFeature],
        lines: List[str],
        file_path: str
    ) -> AIDetection:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù†ØªÙŠØ¬Ø© ÙƒØ´Ù ÙˆØ§Ø­Ø¯Ø©"""
        risk_level = self._confidence_to_risk(confidence)
        affected_lines = self._find_affected_lines(features, lines)
        
        vulnerability_info = self._get_vulnerability_info(category)
        
        return AIDetection(
            vulnerability_type=f"{category.value}_vulnerability",
            category=category,
            risk_level=risk_level,
            confidence=confidence,
            evidence=[f.description for f in features[:5]],
            context={
                "feature_count": len(features),
                "max_feature_value": max(f.value for f in features),
                "affected_lines_count": len(affected_lines)
            },
            recommendations=vulnerability_info["recommendations"],
            affected_lines=affected_lines,
            cwe_id=vulnerability_info["cwe"],
            owasp_category=vulnerability_info["owasp"]
        )
    
    def _confidence_to_risk(self, confidence: float) -> RiskLevel:
        """ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø¥Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ù…Ø®Ø§Ø·Ø±"""
        if confidence > 0.8:
            return RiskLevel.CRITICAL
        elif confidence > 0.6:
            return RiskLevel.HIGH
        elif confidence > 0.4:
            return RiskLevel.MEDIUM
        elif confidence > 0.2:
            return RiskLevel.LOW
        else:
            return RiskLevel.INFO
    
    def _find_affected_lines(self, features: List[CodeFeature], lines: List[str]) -> List[int]:
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„Ù…ØªØ£Ø«Ø±Ø©"""
        affected_lines = []
        
        for i, line in enumerate(lines, 1):
            for feature in features:
                if feature.value > 0 and feature.name.lower() in line.lower():
                    affected_lines.append(i)
                    break
        
        return list(set(affected_lines))[:20]  # Ø­Ø¯ Ø£Ù‚ØµÙ‰ 20 Ø³Ø·Ø±
    
    def _get_vulnerability_info(self, category: VulnerabilityCategory) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø«ØºØ±Ø©"""
        vulnerability_db = {
            VulnerabilityCategory.INJECTION: {
                "cwe": "CWE-89",
                "owasp": "A1:2017 Injection",
                "recommendations": [
                    "Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ù…ÙØ¹Ø¯Ù‘Ø© (Prepared Statements)",
                    "ÙØ­Øµ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…",
                    "Ø§Ø³ØªØ®Ø¯Ù… ORM Ù…Ø«Ù„ SQLAlchemy Ø£Ùˆ Hibernate"
                ]
            },
            VulnerabilityCategory.AUTHENTICATION: {
                "cwe": "CWE-306",
                "owasp": "A2:2017 Broken Authentication",
                "recommendations": [
                    "ØªÙØ¹ÙŠÙ„ MFA Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†",
                    "Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¬Ù„Ø³Ø§Øª Ø¢Ù…Ù†Ø©",
                    "ØªØ·Ø¨ÙŠÙ‚ Ø³ÙŠØ§Ø³Ø© ÙƒÙ„Ù…Ø§Øª Ù…Ø±ÙˆØ± Ù‚ÙˆÙŠØ©"
                ]
            },
            VulnerabilityCategory.SENSITIVE_DATA: {
                "cwe": "CWE-200",
                "owasp": "A3:2017 Sensitive Data Exposure",
                "recommendations": [
                    "ØªØ´ÙÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø© Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù†Ù‚Ù„ ÙˆØ§Ù„ØªØ®Ø²ÙŠÙ†",
                    "Ø§Ø³ØªØ®Ø¯Ø§Ù… HTTPS Ø¯Ø§Ø¦Ù…Ø§Ù‹",
                    "ØªØ¬Ù†Ø¨ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø©"
                ]
            },
            VulnerabilityCategory.CRYPTOGRAPHY: {
                "cwe": "CWE-327",
                "owasp": "A6:2021 Cryptographic Failures",
                "recommendations": [
                    "Ø§Ø³ØªØ®Ø¯Ù… Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª ØªØ´ÙÙŠØ± Ø­Ø¯ÙŠØ«Ø© (AES-256, SHA-256)",
                    "ØªØ¬Ù†Ø¨ Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ù‚Ø¯ÙŠÙ…Ø© (MD5, SHA1)",
                    "Ø§Ø³ØªØ®Ø¯Ù… salt Ù„Ù„ØªØ®Ø²ÙŠÙ†"
                ]
            },
            VulnerabilityCategory.INPUT_VALIDATION: {
                "cwe": "CWE-20",
                "owasp": "A1:2021 Broken Access Control",
                "recommendations": [
                    "ÙØ­Øµ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª",
                    "Ø§Ø³ØªØ®Ø¯Ø§Ù… whitelists Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† blacklists",
                    "ØªØ­Ø¯ÙŠØ¯ Ø­Ø¬Ù… Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª"
                ]
            },
        }
        
        return vulnerability_db.get(category, {
            "cwe": "CWE-000",
            "owasp": "Unknown",
            "recommendations": ["Ø±Ø§Ø¬Ø¹ Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ù…Ø§Ø±Ø³Ø§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ©"]
        })
    
    def _calculate_risk_score(self, detections: List[AIDetection]) -> int:
        """Ø­Ø³Ø§Ø¨ Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ø®Ø§Ø·Ø±"""
        if not detections:
            return 100
        
        total_score = 0
        for detection in detections:
            weight = {
                RiskLevel.CRITICAL: 20,
                RiskLevel.HIGH: 15,
                RiskLevel.MEDIUM: 10,
                RiskLevel.LOW: 5,
                RiskLevel.INFO: 2
            }
            total_score += weight.get(detection.risk_level, 5) * detection.confidence
        
        return max(0, min(100, 100 - int(total_score)))
    
    def _generate_recommendations(self, detections: List[AIDetection]) -> List[str]:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª"""
        recommendations = set()
        
        for detection in detections:
            recommendations.update(detection.recommendations)
        
        return list(recommendations)[:10]


def scan_directory_ai(target_dir: str, output_path: str = None) -> Dict[str, Any]:
    """ÙØ­Øµ Ù…Ø¬Ù„Ø¯ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
    import time
    start_time = time.time()
    
    detector = AIVulnerabilityDetector()
    results = []
    total_files = 0
    total_vulnerabilities = 0
    
    # Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©
    supported_extensions = {
        '.py', '.js', '.ts', '.java', '.cs', '.go', '.rs',
        '.php', '.cpp', '.c', '.rb', '.html', '.xml', '.json'
    }
    
    for root, dirs, files in os.walk(target_dir):
        # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ø®Ø§ØµØ©
        dirs[:] = [d for d in dirs if not d.startswith(('.', '__', 'venv', 'node_modules'))]
        
        for file in files:
            if Path(file).suffix in supported_extensions:
                file_path = os.path.join(root, file)
                total_files += 1
                
                try:
                    result = detector.detect_vulnerabilities(file_path)
                    results.append(analysis_result_to_dict(result))
                    total_vulnerabilities += len(result.detections)
                except Exception as e:
                    logger.error(f"Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ {file_path}: {e}")
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ø®Øµ
    summary = {
        "scan_id": hashlib.md5(str(start_time).encode()).hexdigest()[:8],
        "scan_time": time.strftime("%Y-%m-%d %H:%M:%S"),
        "target_directory": target_dir,
        "total_files_scanned": total_files,
        "total_vulnerabilities": total_vulnerabilities,
        "duration_seconds": round(time.time() - start_time, 2),
        "results": results,
        "ai_model_version": "1.0.0",
        "features_extracted": 24
    }
    
    # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    if output_path:
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=4, ensure_ascii=False)
    
    return summary


# Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¥Ù„Ù‰ Ù‚Ø§Ù…ÙˆØ³
def analysis_result_to_dict(result: AnalysisResult) -> Dict[str, Any]:
    """ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¥Ù„Ù‰ Ù‚Ø§Ù…ÙˆØ³"""
    return {
        "scan_id": result.scan_id,
        "target_file": result.target_file,
        "file_hash": result.file_hash,
        "language": result.language,
        "total_lines": result.total_lines,
        "features": [
            {
                "name": f.name,
                "value": f.value,
                "category": f.category.value,
                "description": f.description
            }
            for f in result.features
        ],
        "detections": [
            {
                "vulnerability_type": d.vulnerability_type,
                "category": d.category.value,
                "risk_level": d.risk_level.name,
                "confidence": round(d.confidence, 4),
                "evidence": d.evidence,
                "context": d.context,
                "recommendations": d.recommendations,
                "affected_lines": d.affected_lines,
                "cwe_id": d.cwe_id,
                "owasp_category": d.owasp_category
            }
            for d in result.detections
        ],
        "overall_risk_score": result.overall_risk_score,
        "recommendations": result.recommendations,
        "analysis_time_seconds": round(result.analysis_time, 4)
    }


def main():
    """Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Auto-Guardian AI Vulnerability Detector"
    )
    parser.add_argument(
        "target",
        nargs="?",
        default=".",
        help="Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø£Ùˆ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø±Ø§Ø¯ ÙØ­ØµÙ‡"
    )
    parser.add_argument(
        "--output", "-o",
        help="Ù…Ø³Ø§Ø± Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬"
    )
    parser.add_argument(
        "--file", "-f",
        help="ÙØ­Øµ Ù…Ù„Ù ÙˆØ§Ø­Ø¯ ÙÙ‚Ø·"
    )
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="Ø¹Ø±Ø¶ ØªÙØ§ØµÙŠÙ„ Ø¥Ø¶Ø§ÙÙŠØ©"
    )
    
    args = parser.parse_args()
    
    if args.file:
        # ÙØ­Øµ Ù…Ù„Ù ÙˆØ§Ø­Ø¯
        detector = AIVulnerabilityDetector()
        result = detector.detect_vulnerabilities(args.file)
        print(json.dumps(analysis_result_to_dict(result), indent=4, ensure_ascii=False))
    else:
        # ÙØ­Øµ Ù…Ø¬Ù„Ø¯
        output_path = args.output or "public/data/ai_scan_results.json"
        results = scan_directory_ai(args.target, output_path)
        
        print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘        ğŸ¤– Auto-Guardian AI Vulnerability Detector          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙØ­ÙˆØµØ©: {results['total_files_scanned']:<30} â•‘
â•‘  Ø§Ù„Ø«ØºØ±Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©: {results['total_vulnerabilities']:<30} â•‘
â•‘  Ù…Ø¯Ø© Ø§Ù„ÙØ­Øµ: {results['duration_seconds']} Ø«Ø§Ù†ÙŠØ©{' '*27} â•‘
â•‘  Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {results['ai_model_version']:<33} â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """)


if __name__ == "__main__":
    main()
